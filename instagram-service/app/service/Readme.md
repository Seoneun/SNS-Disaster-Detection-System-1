안녕하세요 스마트 sns재난 모니터링ㄱ 시스템 서비스를 출품한 모아이팀 입니다.

저희가 이 서비스를 기획하게 된 이유는 코로나라는 팬데믹 상황 떄문입니다. 코로나로 인해 사람들은 언제든 재난이 닥칠 수 있다는 사실을 인식하게 되었고 누구도 예상하지 못한채 찾아온 코로나 상황처럼 다른 종류의 재난 역시 예상치 못하게 발생할 수 있습니다. 우리는 재난 상황을 최대한 빠르게 알아차리고 상황을 파악하는 것이 중요하다고 생각하였기 때문에 저희는 개발목표로 이런 재난상황의 신속한 파악으로 잡았습니다.

그렇게 SNS상의 비정형 데이터 분석을 통한 실시간 스마트 SNS 재난 모니터링 상황 보드를 제작하기로 하였습니다. 이 모니터링 시스템은 우선 재난 키워드별로 실시간으로 올라오는 소셜 데이터 언급량을 시각화하여 보여줍니다. 또한 소셜 데이터의 언급 내용을 분석해 현재 언급되고 있는 재난 상황의 맥락을 보여줄 것입니다. 즉 재난 데이터를 실시간으로 수집하고, 데이터에 대한 정량적 통계와 비정형 데이터 분석 결과를 제공하는 것이 저희 프로젝트의 목표입니다.

저희 스마트 SNS 재난 모니터링 서비스의 모습입니다. 저희 서비스 디자인은 템플릿을 사용하지 않았고 CSS를 일일히 코딩해가며 직접 디자인을 하였습니다. 

/ 저희 서비스의 주 기능은 재난 언급량 제공, sns 현황 제공, 이상 상태 시 메일 전송 입니다. - 5분 단위로 매 1000 여건의 데이터를 실시간으로 크롤링해 재난 키워드의 언급량을 제공합니다. 그리고 머신러닝을 통해 이 데이터들이 유의미한 텍스트임을 판별해내어 실시간 SNS 현황으로 제공합니다. 재난 언급량은 chart.js라는 라이브러리를 이용하여 바 차트와 라인 차트로 시각화하여 보여줍니다. 추가적으로, 노드메일러를 이용하여 비정상적으로 특정 재난의 언급량이 급증할 시 이를 감지하여 관리자에게 메일을 전송합니다. 사용자가 직접 관리자에게 메일을 전송할 수도 있습니다. 




----------------------------순서도 (플로우차트 앞부분에 넣어둠) ---------------------------------
다음은 아키텍처입니다. 저희 프로젝트는 퍼블리싱, 프론트엔드, 백엔드, 데이터베이스, 데이터수집, 머신러닝 파트로 이루어져 있습니다. 마이크로 서비스 MSA 아키텍처를 이용해 컴포넌트별로 서비스를 나누었으며 각 서비스는 본인만의 데이터베이스를 가지고 있습니다. 도커 컴포즈를 이용해 모든 컴포넌트들을 도커라이징해 관리했으며 프론트엔드는 Vue js , Vuex 를 이용했습니다. 프론트엔드에서 요청이 들어오면 API 게이트웨이로써 nginx 를 이용해 컨테이너 서비스들에게 리버스 프록시로 요청을 전송합니다. 오른쪽은 작성한 컴포즈 파일의 일부분입니다.  

네이버 서비스, 인스타그램 서비스, 트위터 서비스는  각자 독립적인 데이터베이스를 가지고 있으며  비동기 기반 스케줄러를 사용해 일정 시간 주기로 새로운 데이터를 수집해  DB 데이터베이스에  저장하면서 누적합니다. 

또 일정 시간 주기로 머신러닝 서비스에서 네이버서비스, 인스타그램서비스, 트위터서비스에 누적된 데이터를 가져와 자연어처리를 이용해 의미있는 재난 메시지인지 판별하는 과정을 거칩니다. 

------------------------여기까지 도커 사진 ----------------------------------
다음으로 API 서버 배포입니다. 배포시에는 앞단에 애플리케이션 로드 밸런서를 두어 기존 Nginx 가 해주던 url 별 라우팅을 대신하도록 구성했습니다. 각 인스턴스에는 서비스 어플리케이션과 도커 이미지를 기반으로 생성된 데이터베이스가 존재합니다.

------------------------배포 1 끝 배포 2 시작 ----------------------------------
클라이언트는  클라우드 Route53 과 클라우드 프론트를 이용해 원본 버킷의 데이터를 가져와 제공할 수있도록 구성했으며  SSL 을 발급받아 HTTPS 를 적용했습니다. 
------------------------------------------------------------------------------------------


데이터 수집부분의 구현 내용에 대해 설명드리겠습니다. 트위터, 인스타그램,네이버블로그 세 개의 SNS 에서 데이터를 수집했습니다. 트위터와 네이버는 제공하는 API 를 이용해 데이터를 수집했고 인스타그램 같은 경우는 API 를 제공하지 않아, 셀레니움과 뷰티풀수프를 이용해 봇을 만들어 데이터를 직접 수집했습니다. 

인스타그램 크롤러는 FAST API 프레임워크 이용했고 컨테이너 빌드시 구글 크롬과 크롬 드라이버를 집어넣어 컨테이너 내부에서 헤드리스 크롬으로 천여개의 데이터를 크롤링할 수 있도록 했으며 스케줄러를 이용하여 같은 간격으로 크롤링코드가 실행되도록 하였습니다. 크롤링한 데이터는 MYSQL 컨테이너 데이터베이스에 저장합니다.

트위터와 네이버블로그는 Express 프레임워크에서 API 를 호출해 (엔터) 컨테이너 내부에서 데이터를 수집 후 mongo DB 에 저장하는 방식입니다.

저희는 AI모델을 사용하였는데 NLP모델을 이용하였습니다. 해당 모델의 목적은 SNS에서 크롤링 해온 데이터 중 재난과 관련된 유의미한 데이터를 추출하는 것입니다. 해당 기법으로 비지도학습인 클러스터링 기법을 선택해 모델을 적용했습니다. 문장을 클러스터링을 하기 위해 자연어를 벡터로 표현하여야 했고 이를 위한 모델로 패스트텍스트에 씨씨케이오삼백빈의 Pretrained된 파일을 사용한 한국어 모델을 사용했습니다. 해당 모델은 한국어 데이터 셋에 대해 학습된 모델입니다. 때문에 영어나 이모티콘 등의 언어들은 불순물로 취급되어 학습에 방해가 돼 해당 언어들은 정규표현식을 사용해 전처리하고 모델에 넣어 벡터화를 진행했습니다. 인풋 데이터로는 JSON 형식의 딕셔너리를 받아 content key에 해당하는 values 값을 뽑아 이를 데이터로 활용했습니다.

 저희가 SNS에서 크롤링한 데이터는 문단 단위의 비정형 데이터로 각 데이터들은 벡터화하기 위해선 데이터를 문장단위로 나눠줘야 했습니다. 저희는 이 과정을 수행하기 위해  KSS라는 깃허브 오픈소스 Korean Sentence Splitter를 사용해 문단을 문장별로 추출해내고 각 문단에 필요한 대표군을 인위적으로 추가하여 데이터 셋을 

scikitlearn모듈의 Kmeans 알고리즘을 사용해 클러스터링을 진행했습니다. 크롤링된 데이터 레코드들당 문장의 개수가 달라 실험적으로 테스트해봤을 때, 군집의 개수를 늘리는 것이 학습 결과가 좋아 최대한 군집을 많이 분류해내어 유의미한 데이터셋을 추출하였습니다. 추출하는 방식은 추가적으로 유용하다고 판단되는 데이터를 추가하여 해당 데이터를 중심으로 클러스터링 후 그 데이터와 라벨링이 같은 문장들을 추출해냈습니다. 해당 문장들에 해당하는 기본 데이터들과 합쳐 JSON 형식의 딕셔너리로 다시 만들어 백엔드의 app.py로 전달했습니다.

그리고 저희 서비스의 기대효과 입니다. 여러 사람들이 올린 재난 관련 내용을 통해 단시간에 상황을 파악하여 대응할 수 있습니다. §여러 플랫폼에 흩어져 있는 재난 관련 소셜 정보들을 한 곳에서 취합하여 볼 수 있습니다. 또 재난 상황과 연관된 네티즌들이 전하는 정보를 통해, 보다 구체적으로 상황을 파악할 수 있다. § 재난 키워드 언급량 추이를 통해 재난의 영향력을 쉽게 파악할 수 있으며 §빠른 상황파악과 영향력 정도 파악을 통해 대비책을 서둘러 마련함으로써 현장대응에 도움을 줄 수 있습니다.
또한, 저희 서비스에서 생성된 데이터를 바탕으로 새로운 부가가치를 창출할 수 있습니다. §재난 발생 빈도 분석, §재난 예측, §재난 대응 자동화등이 그 예시입니다.




이제 저희 서비스를 시연하도록 하겠습니다.

(데모영상)

시나리오: 
#scene1
우상은 컴퓨터앞에 앉아 docker compose up --build 를 쓴다. 타다닥 올라오는 로그들을 녹화 
다 올라가면 db에 들어가는 로그들을 보면서 설명. ex) 크롤링을 해서 디비에 올라갔다, 가져와서 nlp모델에 들어가서 처리가 되고있다 등등.. 

#scene2
서비스 사용하는 장면 보여주기. 

대본: 
대시보드
어떤 내용있는지 소개 - 실시간 재난 언급량 순위, 바 차트, 시간대별 재난 언급량 라인 차트, 실시간 sns현황
실시간으로 바뀌고 있다는 것을 알려줌. - 언급량은 5분마다 갱신, sns는 10분마다 갱신
차트 페이지
시간대별 재난 언급량 그래프를 각 재난별로 나누어 보여주는 페이지입니다.
sns페이지
대시보드에 있었던 sns현황을 플랫폼별로 구분하여 보여줍니다.
메일 발송
다음은 메일 발송 기능입니다. 특정 재난이 비정상적으로 급증할시 이상상태 알림으로 관리자에게 알림을 보낼 수 있습니다. 또 대시보드 사용자가 판단해 메일을 전송할 수 있습니다.
메일을 실제로 받은 화면입니다.
핑
헬스 체크.
최근 10개의 데이터 로그를 확인할 수 있도록 제공. 

여기까지 저희의 서비스를 소개를 마치도록 하겠습니다. 배포된 URL을 통해 직접 서비스를 확인해보실 수 있습니다. 이상 팀 모아이였습니다. 감사합니다.
